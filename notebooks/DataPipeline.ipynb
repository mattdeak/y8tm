{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "class FrameConverter:\n",
    "    def __init__(self, X_transforms=[], y_transforms=[], repeat_count=1, n_parallel=1):\n",
    "        self.filename_base = '/home/data/full/frame/{}{}.tfrecord'\n",
    "        self.X_transforms = X_transforms\n",
    "        self.y_transforms = y_transforms\n",
    "        self.repeat_count = repeat_count\n",
    "        self.n_parallel = n_parallel\n",
    "        \n",
    "        self.keys_to_features = {\n",
    "            'rgb': tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "            'audio': tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "        }\n",
    "        self.key_to_label = {\n",
    "            'labels': tf.VarLenFeature(tf.int64)\n",
    "        }\n",
    "        \n",
    "    def get_data(self, filename):\n",
    "        y, X = tf.parse_single_sequence_example(filename,\n",
    "                                                self.key_to_label,\n",
    "                                                self.keys_to_features)\n",
    "        # X is still bytes; convert to float\n",
    "        X['audio'] = tf.cast(tf.decode_raw(X['audio'], tf.uint8), tf.float32)\n",
    "        X['rgb'] = tf.cast(tf.decode_raw(X['rgb'], tf.uint8), tf.float32)\n",
    "\n",
    "        # now apply custom transformations\n",
    "        for transform in self.X_transforms:\n",
    "            X = transform(X)\n",
    "\n",
    "        y = tf.sparse_to_dense(y['labels'].values, [3862], 1)\n",
    "        for transform in self.y_transforms:\n",
    "            y = transform(y)\n",
    "        return X, y\n",
    "    \n",
    "    def make_provider(self, subset, record_indices):\n",
    "        filenames = [self.filename_base.format(subset, index) for index in record_indices]\n",
    "        \n",
    "        dataset = tf.data.TFRecordDataset(filenames)\n",
    "        dataset = dataset.map(self.get_data,\n",
    "                              num_parallel_calls=self.n_parallel)\n",
    "        dataset = dataset.repeat(self.repeat_count)\n",
    "        dataset = dataset.shuffle(buffer_size=256)\n",
    "            \n",
    "        dataset = dataset.batch(1)\n",
    "        dataset = dataset.prefetch(1)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        return iterator\n",
    "    \n",
    "    def make_generator(self, subset, record_indices):\n",
    "        provider = self.make_provider(subset, record_indices)\n",
    "        sess = tf.Session()\n",
    "        next_sample = provider.get_next()\n",
    "        while True:\n",
    "            try:\n",
    "                yield sess.run(next_sample)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"Iterations exhausted\")\n",
    "                break\n",
    "    \n",
    "frame_converter = FrameConverter()\n",
    "train_generator = frame_converter.make_generator('train', [2500])\n",
    "valid_generator = frame_converter.make_generator('validate', [2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Flatten, Add\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "n_classes = 3862\n",
    "rgb_in = Input((None, 1024), name='rgb')\n",
    "audio_in = Input((None, 128), name='audio')\n",
    "rgb_mid = GRU(64, activation='relu')(rgb_in)\n",
    "audio_mid = GRU(64, activation='relu')(audio_in)\n",
    "combined_mid = Add()([rgb_mid, audio_mid])\n",
    "out = Dense(32, activation='relu')(combined_mid)\n",
    "out = Dense(n_classes, activation='softmax')(out)\n",
    "model = Model([rgb_in, audio_in], out)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "30/30 [==============================] - 13s 438ms/step - loss: 0.0152 - acc: 0.9989 - val_loss: 0.0127 - val_acc: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f385bdd29e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=30, epochs=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3862)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.predict([np.random.random((10, 300, 1024)), np.random.random((10, 300, 128))]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
